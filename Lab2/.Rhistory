2+@
2+2
# Instalacja TensorFlow
install.packages("tensorflow")
library(tensorflow)
install_tensorflow()
y
# Instalacja Keras
install.packages("keras")
library(keras)
install_keras()
# Pobranie danych wejsciowych
library(keras)
cifar <- dataset_cifar10()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(1, 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(dim(X_train)[1], 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(dim(X_train)[1], 32, 32, 3))
X_train <- apply(X_train, c(1, 2, 3), function(x) flatten(x))
gc()
cifar <- dataset_cifar10()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1, 784, 3))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1, 1024, 3))
X_train <- X_train / 255
X_test <- array_reshape(X_test, c(nrow(X_test), 1, 1024, 3))
X_test <- X_test / 255
y_train <- to_categorical(y_train, num_classes = 10)
y_test <- to_categorical(y_test, num_classes = 10)
View(cifar)
View(cifar)
View(cifar)
rm(cifar)
gc()
View(y_train)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(28, 28)) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(32, 32)) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1,1024,3)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
X_train
X_train <- X_train[,,1024,]
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
X_train <- cifar$train$x
cifar <- dataset_cifar10()
gc()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
X_train_input <- as.data.frame.table(X_train)
gc()
install.packages("Rcmdr", dependencies=TRUE)
library(Rcmdr)
# 1.
liczby <- sample(c(1,2,3,4), 100)
# 1.
liczby <- sample(c(1,2,3,4), 100, replace=TRUE)
czynniki <- factor(liczby, levels=c("czerwony", "zielony", "niebieski", "żółty"))
czynniki
# 1.
liczby <- sample(c(1,2,3,4), 100, replace=TRUE)
czynniki <- factor(liczby, levels=1:4)
levels(czynniki) <- c("czerwony", "zielony", "niebieski", "żółty")
print(czynniki)
summary(czynniki)
# 2.
lengths <- Sepal$Length
# 2.
lengths <- Sepal.Length
# 2.
data(iris)
podzialy <- c(4.3, 5.02, 5.74, 6.46, 7.18, 7.9)
dlugosci <- cut(iris$Sepal.Length, breaks=podzialy, labels=c("(4.3,5.02]", "(5.02, 5.74]", "(5.74,6.46]", "(6.46,7.18]", "(7.18,7.9]"), include.lowest=TRUE)
print(dlugosci)
ilosci <- table(dlugosci)
print(ilosci)
# 3.
data(iris)
ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(ponizej_5, iris$Species)
wyniki <- as.data.frame(wyniki)
rownames(wyniki) <- c("FALSE", "TRUE")
colnames(wyniki) <- levels(iris$Species)
View(wyniki)
# 3.
data(iris)
ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(iris$Species, ponizej_5)
wyniki <- table(iris$Species)
dlugosc_ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(dlugosc_ponizej_5, iris$Species)
rownames(wyniki) <- c("FALSE", "TRUE")
print(wyniki)
# 4.
x <- c(1,3,4,7,11,18,29)
x2 <- list(x*2, x/2, sqrt(x))
x2 <- list("x*2"=x*2, "x/2"=x/2, "sqrt(x)"=sqrt(x))
print(x2)
element <- x2[["sqrt(x)"]][2:4]
print(element)
element <- x2[["sqrt(x)"]][3:5]
print(element)
# 4.
x <- c(1,3,4,7,11,18,29)
x2 <- list("x*2"=x*2, "x/2"=x/2, "sqrt(x)"=sqrt(x))
print(x2)
element <- x2[["sqrt(x)"]][3:5]
print(element)
# 5.
ramka <- data.frame(
'wiek' = c(25, 31, 23, 52, 76, 49, 26),
'wzrost' = c(177, 163, 190, 179, 163, 183, 164),
'waga' = c(57, 69, 83, 75, 70, 83, 53),
'płeć' = c('K', 'K', 'M', 'M', 'K', 'M', 'K'),
row.names = c('Kasia', 'Ania', 'Tomek', 'Piotr', 'Maria', 'Karol', 'Sylwia')
)
print(ramka)
# 5.
ramka <- data.frame(
'wiek' = c(25, 31, 23, 52, 76, 49, 26),
'wzrost' = c(177, 163, 190, 179, 163, 183, 164),
'waga' = c(57, 69, 83, 75, 70, 83, 53),
'płeć' = c('K', 'K', 'M', 'M', 'K', 'M', 'K'),
row.names = c("Kasia", "Ania", "Tomek", "Piotr", "Maria", "Karol", "Sylwia")
)
print(ramka)
ramka$płeć = c("K", "M", "K", "K", "K", "K", "M")
print(ramka)
# 6.
data(swiss)
dane <- swiss[c(1, 2, 3, 10, 11, 12, 13), c("Examination", "Education", "Infant.Mortality")]
print(dane)
#Q1 A
library(readxl)
install.packages(readxl)
install.packages("readxl")
install.packages("readxl")
#Q1 A
library(readxl)
file_path <- "C:\\Users\\klino\\Pulpit\\Fiverr project 2\\OECDpopulation.xlsx"
OECD <- read_excel(file_path)
head(OECD)
#q1 B:
OECD[OECD$P2021<OECD$P2020,c("Country")]
#Q1 C:
OECD$Change20_21 <- round(((OECD$P2021 - OECD$P2020) / OECD$P2020) * 100, 2)
head(OECD)
#Q1 D
OECD[which.max(OECD$P2000-OECD$P2021),]
#Q1 E#
average_row <- c("Average", mean(OECD$P2000), mean(OECD$P2005), mean(OECD$P2010), mean(OECD$P2015), mean(OECD$P2020), mean(OECD$P2021), mean(OECD$Change20_21))
v
#Q1 E
average_row <- data.frame(
Country = "Average",
P2000 = mean(OECD$P2000),
P2005 = mean(OECD$P2005),
P2010 = mean(OECD$P2010),
P2015 = mean(OECD$P2015),
P2020 = mean(OECD$P2020),
P2021 = mean(OECD$P2021),
Change20_21 = mean(OECD$Change20_21)
)
OECD <- rbind(OECD, average_row)
tail(OECD, 1)
#Q1 E
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = round(mean(OECD$P2020)),
P2021 = round(mean(OECD$P2021)),
Change20_21 = round(((mean_column_values["P2021"] - mean_column_values["P2020"]) / mean_column_values["P2020"]) * 100, 2)
)
OECD <- rbind(OECD, average_row)
#Q1 E
mean2021 <- round(mean(OECD$P2021))
mean2020 <- round(mean(OECD$P2020))
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = mean2020,
P2021 = mean2021,
Change20_21 = round(((mean2021 - mean2020) / mean2020) * 100, 2)
)
#Q1 A
library(readxl)
file_path <- "C:\\Users\\klino\\Pulpit\\Fiverr project 2\\OECDpopulation.xlsx"
OECD <- read_excel(file_path)
head(OECD)
#q1 B:
OECD[OECD$P2021<OECD$P2020,c("Country")]
#Q1 C:
OECD$Change20_21 <- round(((OECD$P2021 - OECD$P2020) / OECD$P2020) * 100, 2)
head(OECD)
#Q1 D
OECD[which.max(OECD$P2000-OECD$P2021),]
#Q1 E
mean2021 <- round(mean(OECD$P2021))
mean2020 <- round(mean(OECD$P2020))
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = mean2020,
P2021 = mean2021,
Change20_21 = round(((mean2021 - mean2020) / mean2020) * 100, 2)
)
OECD <- rbind(OECD, average_row)
tail(OECD, 1)
View(average_row)
#Q1 F
write.table(OECD, file = "oecd.txt", sep = ",", row.names = FALSE)
cat("Data frame has been saved to oecd.txt\n")
file_path <- "oecd.txt"
file_contents <- readLines(file_path)
cat(file_contents, sep = "\n")
#Q 1 G:
percent_change <- OECD$Change20_21 / 100
pop2022 <- round(OECD$P2021 * (1 + percent_change))
OECD$Pop.2023 <- round(pop2022 * (1 + percent_change))
mean_2023 <- mean(OECD$Pop.2023)
OECD[nrow(OECD), "Pop.2023"] <- mean_2023
print(head(OECD))
print(OECD[nrow(OECD),])
#Q1 H: Need to work on this:
count_above_10M <- sum(OECD$P2000 > 10000000)
countries_above_10M <- subset(OECD, OECD$P2000 > 10000000)
average_pop_above_10M <- round(mean(countries_above_10M$P2000))
print(count_above_10M)
print(average_pop_above_10M)
setwd("C:/Users/klino/Pulpit/Studia magisterskie sem 2/ZBDIED/Lab2")
# Ćw. 1.
data(airquality)
str(airquality)
airquality(100:105, 5:6)
str(airquality)
airquality[100:105, 5:6]
dim(airquality)
dim(airquality[,])
dim(airquality[5:6])
head(airquality)
head(airquality[5:6])
tail(airquality)
tail(airquality[1])
tail(airquality[[1])
tail(airquality[[1]])
tail(airquality)
tail(airquality[1])
tail(airquality[[1]])
vars <- c("Wind", "Temp")
airquality[100:105, vars]
# Ćw. 2.
fn <- system.file("csv", "weather.csv", package="rattle")
file.show(fn)
data <- read.csv("https://rattle.togaware.com/weather.csv")
head(data)
# Ćw. 3.
# setwd(...)
t1 <- read.table("titanic.csv", header=TRUE, sep=",")
t2 <- read.csv("titanic.csv", header=TRUE, sep=",", quote="\"", dec=".",
fill=TRUE, comment.char="")
t3 <- read.csv("titanic.csv")
head(t2)
sum(t2, [, "survived"])
sum(t2[, "survived"])
sum(t2[, "Survived"])
# Ćw. 4.
schowek <- read.table(file("clipboard"), header=TRUE, sep="\t")
schowek
# Ćw. 5.
Veg <- read.table(file="Vegetation2.txt", header=TRUE)
names(Veg)
str(Veg)
# Ćw. 6.
m <- mean(Veg$R)
m1 <- mean(Veg$R[Veg$Transect == 1])
m2 <- mean(Veg$R[Veg$Transect == 2])
m3 <- mean(Veg$R[Veg$Transect == 3])
m4 <- mean(Veg$R[Veg$Transect == 4])
m5 <- mean(Veg$R[Veg$Transect == 5])
m6 <- mean(Veg$R[Veg$Transect == 6])
m7 <- mean(Veg$R[Veg$Transect == 7])
m8 <- mean(Veg$R[Veg$Transect == 8])
ms <- c(m1, m2, m3, m4, m5, m6, m7, m8)
ms
tapply(Veg$R, Veg$Transect, mean)
tapply(X = Veg$R, INDEX = Veg$Transect, FUN = mean)
Me <- tapply(Veg$R, Veg$Transect, mean)
Sd <- tapply(Veg$R, Veg$Transect, sd)
Le <- tapply(Veg$R, Veg$Transect, length)
params <- c(Me, Sd, Le)
params
# Ćw. 7.
sapply(Veg[, 5:9], FUN=mean)
lapply(Veg[, 5:9], FUN=mean)
results <- sapply(USArrests, FUN=sum)
results
# Ćw. 8.
dataset(USArrests)
# Ćw. 8.
data(USArrests)
USArrests
# Ćw. 8.
data(USArrests)
results <- sapply(USArrests, FUN=sum)
results
weekdays()
weekdays(7)
# Ćw. 8.
# 1.
temp <- lapply(1:5, FUNC=sample(1:100, 5, replace=TRUE))
# Ćw. 8.
# 1.
temp <- lapply(1:5, FUN=sample(1:100, 5, replace=TRUE))
# Ćw. 8.
# 1.
temp <- lapply(1:5, FUN=sample)
temp[0]
temp[[0]]
# Ćw. 8.
# 1.
temp <- lapply(c(5,5,5,5,5), FUN=sample)
names(temp) <- c("Poniedziałek", "Wtorek", "Środa", "Czwartek", "Piątek", "Sobota",
"Niedziela")
# Ćw. 8.
# 1.
temp <- lapply(c(5,5,5,5,5,5,5), FUN=sample)
names(temp) <- c("Poniedziałek", "Wtorek", "Środa", "Czwartek", "Piątek", "Sobota",
"Niedziela")
temp
mins <- sapply(temp, FUN=min)
maxs <- sapply(temp, FUN=max)
mins
maxs
