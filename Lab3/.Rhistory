library(keras)
cifar <- dataset_cifar10()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(1, 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(dim(X_train)[1], 1024))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(dim(X_train)[1], 32, 32, 3))
X_train <- apply(X_train, c(1, 2, 3), function(x) flatten(x))
gc()
cifar <- dataset_cifar10()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1, 784, 3))
# Zmiana rozmiaru obrazkow do warstwy liniowej (1 x 32*32)
# i konwersja wartosci pikseli do zakresu [0, 1]
# Liczba klas = 10
X_train <- array_reshape(X_train, c(nrow(X_train), 1, 1024, 3))
X_train <- X_train / 255
X_test <- array_reshape(X_test, c(nrow(X_test), 1, 1024, 3))
X_test <- X_test / 255
y_train <- to_categorical(y_train, num_classes = 10)
y_test <- to_categorical(y_test, num_classes = 10)
View(cifar)
View(cifar)
View(cifar)
rm(cifar)
gc()
View(y_train)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(28, 28)) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(32, 32)) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1,1024,3)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
# Tworzenie modelu zgodnie z instrukcja laboratoryjna
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu", input_shape = c(1024)) %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 10, activation = "softmax")
# Informacje o modelu
summary(model)
# Kompilowanie modelu
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
# Trenowanie modelu
history <- model %>%
fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.15)
X_train
X_train <- X_train[,,1024,]
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
X_train <- cifar$train$x
cifar <- dataset_cifar10()
gc()
X_train <- cifar$train$x
X_test <- cifar$test$x
y_train <- cifar$train$y
y_test <- cifar$test$y
X_train_input <- as.data.frame.table(X_train)
gc()
install.packages("Rcmdr", dependencies=TRUE)
library(Rcmdr)
# 1.
liczby <- sample(c(1,2,3,4), 100)
# 1.
liczby <- sample(c(1,2,3,4), 100, replace=TRUE)
czynniki <- factor(liczby, levels=c("czerwony", "zielony", "niebieski", "żółty"))
czynniki
# 1.
liczby <- sample(c(1,2,3,4), 100, replace=TRUE)
czynniki <- factor(liczby, levels=1:4)
levels(czynniki) <- c("czerwony", "zielony", "niebieski", "żółty")
print(czynniki)
summary(czynniki)
# 2.
lengths <- Sepal$Length
# 2.
lengths <- Sepal.Length
# 2.
data(iris)
podzialy <- c(4.3, 5.02, 5.74, 6.46, 7.18, 7.9)
dlugosci <- cut(iris$Sepal.Length, breaks=podzialy, labels=c("(4.3,5.02]", "(5.02, 5.74]", "(5.74,6.46]", "(6.46,7.18]", "(7.18,7.9]"), include.lowest=TRUE)
print(dlugosci)
ilosci <- table(dlugosci)
print(ilosci)
# 3.
data(iris)
ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(ponizej_5, iris$Species)
wyniki <- as.data.frame(wyniki)
rownames(wyniki) <- c("FALSE", "TRUE")
colnames(wyniki) <- levels(iris$Species)
View(wyniki)
# 3.
data(iris)
ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(iris$Species, ponizej_5)
wyniki <- table(iris$Species)
dlugosc_ponizej_5 <- iris$Sepal.Length < 5
wyniki <- table(dlugosc_ponizej_5, iris$Species)
rownames(wyniki) <- c("FALSE", "TRUE")
print(wyniki)
# 4.
x <- c(1,3,4,7,11,18,29)
x2 <- list(x*2, x/2, sqrt(x))
x2 <- list("x*2"=x*2, "x/2"=x/2, "sqrt(x)"=sqrt(x))
print(x2)
element <- x2[["sqrt(x)"]][2:4]
print(element)
element <- x2[["sqrt(x)"]][3:5]
print(element)
# 4.
x <- c(1,3,4,7,11,18,29)
x2 <- list("x*2"=x*2, "x/2"=x/2, "sqrt(x)"=sqrt(x))
print(x2)
element <- x2[["sqrt(x)"]][3:5]
print(element)
# 5.
ramka <- data.frame(
'wiek' = c(25, 31, 23, 52, 76, 49, 26),
'wzrost' = c(177, 163, 190, 179, 163, 183, 164),
'waga' = c(57, 69, 83, 75, 70, 83, 53),
'płeć' = c('K', 'K', 'M', 'M', 'K', 'M', 'K'),
row.names = c('Kasia', 'Ania', 'Tomek', 'Piotr', 'Maria', 'Karol', 'Sylwia')
)
print(ramka)
# 5.
ramka <- data.frame(
'wiek' = c(25, 31, 23, 52, 76, 49, 26),
'wzrost' = c(177, 163, 190, 179, 163, 183, 164),
'waga' = c(57, 69, 83, 75, 70, 83, 53),
'płeć' = c('K', 'K', 'M', 'M', 'K', 'M', 'K'),
row.names = c("Kasia", "Ania", "Tomek", "Piotr", "Maria", "Karol", "Sylwia")
)
print(ramka)
ramka$płeć = c("K", "M", "K", "K", "K", "K", "M")
print(ramka)
# 6.
data(swiss)
dane <- swiss[c(1, 2, 3, 10, 11, 12, 13), c("Examination", "Education", "Infant.Mortality")]
print(dane)
#Q1 A
library(readxl)
install.packages(readxl)
install.packages("readxl")
install.packages("readxl")
#Q1 A
library(readxl)
file_path <- "C:\\Users\\klino\\Pulpit\\Fiverr project 2\\OECDpopulation.xlsx"
OECD <- read_excel(file_path)
head(OECD)
#q1 B:
OECD[OECD$P2021<OECD$P2020,c("Country")]
#Q1 C:
OECD$Change20_21 <- round(((OECD$P2021 - OECD$P2020) / OECD$P2020) * 100, 2)
head(OECD)
#Q1 D
OECD[which.max(OECD$P2000-OECD$P2021),]
#Q1 E#
average_row <- c("Average", mean(OECD$P2000), mean(OECD$P2005), mean(OECD$P2010), mean(OECD$P2015), mean(OECD$P2020), mean(OECD$P2021), mean(OECD$Change20_21))
v
#Q1 E
average_row <- data.frame(
Country = "Average",
P2000 = mean(OECD$P2000),
P2005 = mean(OECD$P2005),
P2010 = mean(OECD$P2010),
P2015 = mean(OECD$P2015),
P2020 = mean(OECD$P2020),
P2021 = mean(OECD$P2021),
Change20_21 = mean(OECD$Change20_21)
)
OECD <- rbind(OECD, average_row)
tail(OECD, 1)
#Q1 E
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = round(mean(OECD$P2020)),
P2021 = round(mean(OECD$P2021)),
Change20_21 = round(((mean_column_values["P2021"] - mean_column_values["P2020"]) / mean_column_values["P2020"]) * 100, 2)
)
OECD <- rbind(OECD, average_row)
#Q1 E
mean2021 <- round(mean(OECD$P2021))
mean2020 <- round(mean(OECD$P2020))
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = mean2020,
P2021 = mean2021,
Change20_21 = round(((mean2021 - mean2020) / mean2020) * 100, 2)
)
#Q1 A
library(readxl)
file_path <- "C:\\Users\\klino\\Pulpit\\Fiverr project 2\\OECDpopulation.xlsx"
OECD <- read_excel(file_path)
head(OECD)
#q1 B:
OECD[OECD$P2021<OECD$P2020,c("Country")]
#Q1 C:
OECD$Change20_21 <- round(((OECD$P2021 - OECD$P2020) / OECD$P2020) * 100, 2)
head(OECD)
#Q1 D
OECD[which.max(OECD$P2000-OECD$P2021),]
#Q1 E
mean2021 <- round(mean(OECD$P2021))
mean2020 <- round(mean(OECD$P2020))
average_row <- data.frame(
Country = "Average",
P2000 = round(mean(OECD$P2000)),
P2005 = round(mean(OECD$P2005)),
P2010 = round(mean(OECD$P2010)),
P2015 = round(mean(OECD$P2015)),
P2020 = mean2020,
P2021 = mean2021,
Change20_21 = round(((mean2021 - mean2020) / mean2020) * 100, 2)
)
OECD <- rbind(OECD, average_row)
tail(OECD, 1)
View(average_row)
#Q1 F
write.table(OECD, file = "oecd.txt", sep = ",", row.names = FALSE)
cat("Data frame has been saved to oecd.txt\n")
file_path <- "oecd.txt"
file_contents <- readLines(file_path)
cat(file_contents, sep = "\n")
#Q 1 G:
percent_change <- OECD$Change20_21 / 100
pop2022 <- round(OECD$P2021 * (1 + percent_change))
OECD$Pop.2023 <- round(pop2022 * (1 + percent_change))
mean_2023 <- mean(OECD$Pop.2023)
OECD[nrow(OECD), "Pop.2023"] <- mean_2023
print(head(OECD))
print(OECD[nrow(OECD),])
#Q1 H: Need to work on this:
count_above_10M <- sum(OECD$P2000 > 10000000)
countries_above_10M <- subset(OECD, OECD$P2000 > 10000000)
average_pop_above_10M <- round(mean(countries_above_10M$P2000))
print(count_above_10M)
print(average_pop_above_10M)
# 2.
data(USArrests)
results <- sapply(USArrests, FUN=sum)
results
View(USArrests)
# Ćw 1
Veg <- read.table(file="Vegetation2.txt", header=TRUE)
setwd("C:\Users\klino\Pulpit\Studia magisterskie sem 2\ZBDIED\Lab3")
setwd("C:\\Users\\klino\\Pulpit\\Studia magisterskie sem 2\\ZBDIED\\Lab3")
# Ćw 1
Veg <- read.table(file="Vegetation2.txt", header=TRUE)
plot(x = Veg$BARESOIL, y = Veg$R)
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19))
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19),
pch=8)
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19),
pch=8,
col=2)
# Zaawansowany wykres
Veg$Time2 <- Veg$Time
Veg$Time2[Veg$Time <= 1974] <- 15
Veg$Time2[Veg$Time > 1974] <- 16
Veg$Col2 <- Veg$Time
Veg$Col2[Veg$Time <= 1974] <- 1
Veg$Col2[Veg$Time > 1974] <- 2
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19),
pch=Veg$Time2,
col=Veg$Col2)
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19),
pch=Veg$Time2,
col=Veg$Col2,
cex=1.5)
# Ćw 3
Owls <- read.table(file="Owls.txt", header=TRUE)
names(Owls)
str(Owls)
unique(Owls$Nest)
Owls.ATV <- Owls[Owls$Nest == "AutavauxTV",]
Owls.ATV
plot(x = Owls.ATV$ArrivalTime,
y = Owls.ATV$NegPerChick,
xlab = "Arrival Time", main = "AutavauxTV",
ylab = "Negotiation behaviour")
Owls.Bot <- Owls[Owls$Nest == "Bochet", ]
plot(x = Owls.Bot$ArrivalTime,
y = Owls.Bot$NegPerChick,
xlab = "Arrival Time",
ylab = "Negotiation behaviour", main = "Bochet")
# Automatyzacja
Nest.i <- "Bochet"
Owls.i <- Owls[Owls$Nest == Nest.i, ]
plot(x = Owls.i$ArrivalTime,
y = Owls.i$NegPerChick, xlab = "Arrival Time",
ylab = "Negotiation behaviour", main = "Bochet")
plik <- paste(Nest.i, ".jpg", sep="")
jpeg(file = plik)
plot(x = Owls.i$ArrivalTime, y = Owls.i$NegPerChick,
xlab = "Arrival Time", main = Nest.i,
ylab = "Negotiation behaviour")
dev.off()
plik <- paste("Wykresy/", Nest.i, ".jpg", sep="")
jpeg(file = plik)
plot(x = Owls.i$ArrivalTime, y = Owls.i$NegPerChick,
xlab = "Arrival Time", main = Nest.i,
ylab = "Negotiation behaviour")
plik <- paste("Wykresy/", Nest.i, ".jpg", sep="")
jpeg(file = plik)
plot(x = Owls.i$ArrivalTime, y = Owls.i$NegPerChick,
xlab = "Arrival Time", main = Nest.i,
ylab = "Negotiation behaviour")
dev.off()
AllNests <- unique(Owls$Nest)
for (i in 1:27){
Nest.i <- AllNests[i]
Owls.i <- Owls[Owls$Nest == Nest.i, ]
plik <- paste(Nest.i, ".jpg", sep = "")
jpeg(file = plik)
plot(x = Owls.i$ArrivalTime, y = Owls.i$NegPerChick,
xlab = "Arrival Time",
ylab = "Negotiation behaviour", main = Nest.i)
dev.off()
}
for (i in 1:27){
Nest.i <- AllNests[i]
Owls.i <- Owls[Owls$Nest == Nest.i, ]
plik <- paste("Wykresy/", Nest.i, ".jpg", sep = "")
jpeg(file = plik)
plot(x = Owls.i$ArrivalTime, y = Owls.i$NegPerChick,
xlab = "Arrival Time",
ylab = "Negotiation behaviour", main = Nest.i)
dev.off()
}
# Ćw 4
library(package="lattice")
install.packages("mlmRev")
# Getting started with Lattice
data(Chem97, package="mlmRev")
head(Chem97)
histogram(~ gcsescore, data = Chem97)
histogram(~ gcsescore | factor(score), data = Chem97)
densityplot(~ gcsescore | factor(score), Chem97, groups = gender,
plot.points = FALSE, auto.key = TRUE)
# Plotting Lattice
library(datasets)
xyplot(Ozone ~ Wind, data=airquality)
xyplot(Ozone ~ Wind | Month, data=airquality, layout=c(5,1))
unique(airquality$Month)
p <- xyplot(Ozone ~ Wind, data=airquality)
print(p)
# Ćw 6
bwplot(factor(score) ~ gcsescore | gender, Chem97)
bwplot(gcsescore ~ gender | factor(score), Chem97, layout = c(6, 1))
str(Chem97)
Chem97
str(Chem97)
View(Owls)
View(Chem97)
View(Chem97)
View(Chem97)
# Ćw 6
# 2
Veg <- read.table(file="Vegetation2.txt", header=TRUE)
plot(x = Veg$BARESOIL, y = Veg$R)
Veg$Year <- rep(1)
Veg$Year[Veg$Time == 2002] <- 2
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Scatter plot",
xlim = c(0,45),
ylim = c(4,19),
cex=Veg$Year)
plot(x = Veg$BARESOIL, y = Veg$R,
xlab = "Exposed soil",
ylab = "Species richness",
main = "Wykres Ćw 6",
xlim = c(0,45),
ylim = c(4,19),
cex=Veg$Year)
str(airquality)
